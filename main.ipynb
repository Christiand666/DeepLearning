{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Vi importerer nødvendige biblioteker\n",
    "og definerer globale variabler med stinavne/filnavne \n",
    "'''\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.metrics import f1_score\n",
    "import argparse\n",
    "\n",
    "\n",
    "imagepath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "csvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "croppedImagesPath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "trainingdatacsvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/trainingdata.csv'\n",
    "predictioncsvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n",
    "testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "trainFolder = 'DatasætDeeplearning/TestImages/'\n",
    "\n",
    "#imagepath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "#csvpath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "#croppedImagesPath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "#trainingdatacsvpath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/trainingdata.csv'\n",
    "#predictioncsvpath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n",
    "#testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "#trainFolder = 'DatasætDeeplearning/TestImages/'\n",
    "\n",
    "\n",
    "# imagepath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "# csvpath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "# croppedImagesPath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "# trainingdatacsvpath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/trainingdata.csv'\n",
    "# predictioncsvpath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n",
    "# testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "# trainFolder = 'DatasætDeeplearning/TestImages/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - HELPER\n",
    "Vi definerer en klasse med billededata,\n",
    "som vi kan definere nye obkejter af\n",
    "'''\n",
    "class ImageData:\n",
    "    def __init__(self, path, ymin, xmin, ymax, xmax):\n",
    "        self.path = path\n",
    "        self.xmin = xmin      \n",
    "        self.ymin = ymin        \n",
    "        self.xmax = xmax        \n",
    "        self.ymax = ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - HELPER\n",
    "En funktion som læser data fra .CSV fil, \n",
    "og opretter nye billededata objekter af denne data\n",
    "(.CSV filen indeholder data om, hvor nummerpladen sidder (XY-koordinater))\n",
    "'''\n",
    "def read_image_data():\n",
    "    file = open(csvpath)\n",
    "    csvreader = csv.reader(file)\n",
    "    rows = []\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "            imgdt = ImageData(row[0], int(row[1]), int(row[2]), int(row[3]), int(row[4]))\n",
    "            rows.append(imgdt)\n",
    "    file.close()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 1\n",
    "En funktion som læser billederne ind, \n",
    "og klipper nummerpladen ud,\n",
    "hvorefter de nye billeder gemmes i en ny mappe (croppedImages)\n",
    "'''\n",
    "def crop_images():\n",
    "    imageData = read_image_data()\n",
    "\n",
    "    for id in imageData:\n",
    "        im = Image.open(imagepath + id.path)\n",
    "        im = im.crop( (id.xmin, id.ymin, id.xmax, id.ymax) )\n",
    "        im.save(croppedImagesPath + id.path) \n",
    "        im.close()\n",
    "\n",
    "os.makedirs(croppedImagesPath, exist_ok=True)\n",
    "\n",
    "crop_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 2 \n",
    "Vi definerer en klasse,\n",
    "som kun indeholder billedets navn (filnavn) og nummerpladen (string)\n",
    "'''\n",
    "class PredictionData:\n",
    "    def __init__(self, path, licenseplate):\n",
    "        self.path = path\n",
    "        self.licenseplate = licenseplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - HELPER \n",
    "En funktion som læser data fra .CSV filen,\n",
    "og opretter nye objekter af PredictionData\n",
    "'''\n",
    "def read_prediction_data():\n",
    "    file = open(predictioncsvpath)\n",
    "    csvreader = csv.reader(file)\n",
    "    rows = []\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "            pd = PredictionData(row[0], row[1])\n",
    "            rows.append(pd)\n",
    "    file.close()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 2 \n",
    "En funktion som laver vores data om til one-hot-encoding, som gemmes i en ny .CSV fil.\n",
    "Vi behandler vores data, hvor one-hot-encoding deler vores data op i kategorier, \n",
    "som vores Deep learning algortime kan forstå.\n",
    "'''\n",
    "def onehot_encoding():\n",
    "    predictiondata = read_prediction_data()\n",
    "    numbers = '0123456789'\n",
    "    onehot_encoded = list()\n",
    "    #header = ['img_id', 'text', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    header = ['img_id', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "    with open(trainingdatacsvpath, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for data in predictiondata:\n",
    "            # Vi fjerner T and N fra nummerpladen\n",
    "            datatrimmed = data.licenseplate.replace('T', '')\n",
    "            datatrimmed = datatrimmed.replace('N', '')\n",
    "\n",
    "            # Vi laver nummerpladen om til en liste af nummerene fra nummerpladen\n",
    "            char_to_int = dict((c, i) for i, c in enumerate(numbers))\n",
    "            integer_encoded = [char_to_int[char] for char in datatrimmed] \n",
    "            #print(integer_encoded)\n",
    "\n",
    "            # Vi laver nu one-hot-encode\n",
    "            # 1 bliver sat, hvis det eksisterer i nummerpladen\n",
    "            letter = [0 for _ in range(len(numbers))]\n",
    "            for value in integer_encoded:\n",
    "                letter[value] = 1\n",
    "            \n",
    "            # Billedets navn og den oprindelige nummerplade indsættes også i vores .CSV fil\n",
    "            letter.insert(0, data.path)\n",
    "            #letter.insert(1, data.licenseplate)\n",
    "            \n",
    "            writer.writerow(letter)\n",
    "            onehot_encoded.append(letter)\n",
    "\n",
    "onehot_encoding() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 3 \n",
    "Vi opdeler i et training set og et validation set,\n",
    "hvor vi angiver et seed, hvilket sikre at samme datasæt generes ved samme seed\n",
    "'''\n",
    "with open(trainingdatacsvpath) as trainingcsv:\n",
    "    next(trainingcsv)\n",
    "    file_read = csv.reader(trainingcsv)\n",
    "    array = list(file_read)\n",
    "\n",
    "train, test = train_test_split(array,test_size=0.25,random_state=10) #Det unikke seed nummer er 10\n",
    "#header = ['img_id', 'text', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "header = ['img_id', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Vi tilføjer headers til vores data, tilføjer den til to nye .CSV filer\n",
    "pd.DataFrame(test).to_csv(\"test.csv\",header=header,index=False)\n",
    "pd.DataFrame(train).to_csv(\"train.csv\",header=header,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "trainFolder = 'DatasætDeeplearning/TrainImages/'\n",
    "\n",
    "os.makedirs(testFolder, exist_ok=True)\n",
    "os.makedirs(trainFolder, exist_ok=True)\n",
    "\n",
    "files = glob.glob(testFolder + '*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(trainFolder + '*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "for img in test:\n",
    "   shutil.copy('C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    " + img[0], testFolder + img[0])\n",
    "\n",
    "for img in train:\n",
    "   shutil.copy('C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    " + img[0], trainFolder + img[0])\n",
    "\n",
    "# for img in test:\n",
    "#     shutil.copy('C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], testFolder + img[0])\n",
    "\n",
    "# for img in train:\n",
    "#     shutil.copy('C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], trainFolder + img[0])\n",
    "\n",
    "# for img in test:\n",
    "#    shutil.copy('C:/Users/chris/source/repos/DeepLearning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], testFolder + img[0])\n",
    "\n",
    "# for img in train:\n",
    "#    shutil.copy('C:/Users/chris/source/repos/DeepLearning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], trainFolder + img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (225, 11)\n",
      "CSV head:\n",
      "    img_id  0  1  2  3  4  5  6  7  8  9\n",
      "0  498.jpg  0  1  1  1  1  0  0  0  1  1\n",
      "1  217.jpg  0  1  0  0  1  0  0  1  0  1\n",
      "2  677.jpg  1  1  1  1  0  0  1  1  0  0\n",
      "3  276.jpg  1  1  1  1  1  0  0  0  1  1\n",
      "4  307.jpg  1  1  0  1  1  0  1  0  0  0\n",
      "CSV tail:\n",
      "      img_id  0  1  2  3  4  5  6  7  8  9\n",
      "220  175.jpg  0  1  0  0  1  1  0  1  0  1\n",
      "221  832.jpg  1  1  1  0  1  1  0  0  0  1\n",
      "222  703.jpg  0  1  0  0  1  0  0  1  1  1\n",
      "223  764.jpg  1  1  0  0  1  1  1  0  0  0\n",
      "224  395.jpg  1  1  0  0  1  0  0  0  1  1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 4 \n",
    "Vi laver en funktion, som kan visualisere vores data.\n",
    "Der printes: \n",
    "    - shape (rækker, koloner)\n",
    "    - head (de første 5 rækker)\n",
    "    - tail (de sidste 5 rækker)\n",
    "'''\n",
    "def show_data_from_csv(csv_filepath: str):\n",
    "    csv_data = pd.read_csv(\"test.csv\")\n",
    "    print(\"CSV shape:\", csv_data.shape) \n",
    "    print(\"CSV head:\")\n",
    "    print(csv_data.head()) #det samme som csv_data[:5]\n",
    "    print(\"CSV tail:\")\n",
    "    print(csv_data.tail()) #det samme som csv_data[-5:]\n",
    "\n",
    "show_data_from_csv(\"test.csv\") #\"train.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "En klasse som indeholder billededata fra .CSV fil\n",
    "'''\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = torch.tensor(self.img_labels.iloc[idx, 1:11])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "x = CustomImageDataset('train.csv', trainFolder)\n",
    "y, z = x.__getitem__(0)\n",
    "print(z) #0,1,0,1,0,1,1,0,1,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "Vi opretter en billedetransformer, hvor vi laver billederindstillingerne ens for alle billeder\n",
    "Derefter opretter vi to objekter af CustomImageDataset, \n",
    "som indeholder billededata, samt vores billedetransformer\n",
    "Til sidst definerer vi vores DataLoaders, som vi kan bruge til iterere henover\n",
    "'''\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(25),\n",
    "    transforms.CenterCrop(25),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(0.4915,0.4823,0.4468)\n",
    "])\n",
    "\n",
    "training_data = CustomImageDataset(\n",
    "    'train.csv', trainFolder, transform=TRANSFORM_IMG)\n",
    "\n",
    "test_data = CustomImageDataset(\n",
    "    'test.csv', testFolder, transform=TRANSFORM_IMG)\n",
    "\n",
    "trainloader = DataLoader(training_data, batch_size=10, shuffle=True) #, num_workers=2\n",
    "testloader = DataLoader(test_data, batch_size=64, shuffle=True) # , num_workers=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "En funktion som anvendes til at vise et billede\n",
    "'''\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel: #Der er kun en kanal\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5  #unnormalize, for at få den tilbage til den oprindelige til det neurale netværk (der kan godt udkommenteres)\n",
    "    npimg = img.numpy()\n",
    "    if one_channel: #Hvis der kun er en kanal blier det grå billeder \n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else: #Hvis der er flere kanaler bliver det favet billeder \n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "Dette er vores model klasse\n",
    "'''\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=144, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=60)#linear layer som har input features 84 og output feature 10. \n",
    "\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))#max pooling med en pooling shape på 2x2 over det første 2D convolutional layer\n",
    "        x = self.pool(F.relu(self.conv2(x)))#max pooling med en pooling shape på 2x2 over det andet 2D convolutional layer\n",
    "        x = x.view(-1, 9 * 4 * 4) #Ændrer formen på tensors.\n",
    "        x = F.relu(self.fc1(x))#Linear layer bliver aktiveret via activation function \n",
    "        x = F.relu(self.fc2(x))#Linear layer bliver aktiveret via activation function \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=128,\n",
    "shuffle=True)\n",
    "\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #Bliver brugt til classification Logits --> softmax --> out probabilities opdeling i classes\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/numberplate_experiment_1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader) #Opretter en iterator, hvor den tager trainloader som parameter\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "writer.add_graph(model, images) #Tilføjer grafdata, tager imod vores model og modeldata (images), som pararmetre\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images) #Laver et grid af vores billeder iform af et tensor\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True) #Kalder vores funktion, som vi har defineret højere oppe i koden\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('numberplate_images', img_grid) #Data tilføjes til vores tensorborad\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scalars(total_loss, total_correct, train_set, epoch):\n",
    "    writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    writer.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images): \n",
    "    '''\n",
    "    Genererer forudsigelser og tilsvarende sandsynligheder fra en trænet\n",
    "     netværk og en liste over billeder\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # konvertere output sandsynligheder til forudsagt klasse\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy()) #Fjerner enkeltdimensionelle indgange fra formen af et array\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "    # softmax konverterer en vektor af tal til en vektor af sandsynligheder, hvor sandsynligheden for hver værdi er proportional med den relative skala af hver værdi i vektoren. \n",
    "    #Zip()-funktionen tager iterables (kan være nul eller flere), samler dem i en tupel og returnerer den\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Genererer matplotlib-figur ved hjælp af et trænet netværk sammen med billeder\n",
    "     og etiketter fra en batch, der viser netværkets bedste forudsigelse\n",
    "     med dens sandsynlighed, sammen med den faktiske etiket, farve denne\n",
    "     information baseret på, om forudsigelsen var korrekt eller ej.\n",
    "     Bruger funktionen \"images_to_probs\".\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot billederne i batchen sammen med forudsagte og sande etiketter\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%/n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "                    #Den sammenligner sandsynligheden med billederne og labels \n",
    "                    #grøn jo mere sandsynlig den er og rød hvis den er mindre sandsynlig kan ses når vi køre koden\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6001 (pid 6788), started 4:07:01 ago. (Use '!kill 6788' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3476ffeeb72f3e9e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3476ffeeb72f3e9e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6001;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/runs'  --host localhost --port 6001\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir logs\n",
    "#Højreklik på runs og ændre stinavn\n",
    "#%load_ext tensorboard \n",
    "#%tensorboard --logdir C:/Users/yusuf/Documents/GitHub/DeepLearning/runs --host localhost --port 6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18824/1415000786.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m#.argmax(dim=1).eq(labels).sum().item()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \"\"\"\n\u001b[1;32m-> 1071\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1072\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \"\"\"\n\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1196\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1465\u001b[0m                                     pos_label)\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1294\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1295\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "n_epochs = 100\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "\n",
    "for epoch in range(50):  # looper over dataset 50 gang\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0): #looper igennem data fra vores trainloader\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data #inputs og labels er tensors\n",
    "        print(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() #Vores gradient bliver resat (sættes til 0)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) #Forward -> beregner output tensors ved brug af input tensors\n",
    "        loss.backward() #Beregner gradienten udfra output tensors\n",
    "        total_loss+= loss.item()\n",
    "        total_correct+= get_num_correct(outputs, labels)\n",
    "        optimizer.step() #Optimizeren itererer over parametrene/vores tensors og opdaterer deres gradient \n",
    "\n",
    "        #running_loss += loss.item()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        #.argmax(dim=1).eq(labels).sum().item()\n",
    "        f1_score = f1_score(labels.data.detach().numpy(), outputs.argmax(dim=1))\n",
    "\n",
    "\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            #Tilføjer scalar data til vores tensorboard\n",
    "            writer.add_scalar('Loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(model, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        add_scalars(total_loss, total_correct, training_data, epoch)\n",
    "        writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        writer.add_scalar(\"Accuracy\", total_correct/ len(training_data), epoch)\n",
    "        \n",
    "        print(\"Epoch: %d, Loss: %f\" % (i, float(loss)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/numberplate_experiment')\n",
    "model = Model()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image(\"images\", grid)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0])\n",
      "epoch: 0 total_correct: 235 loss: 17.988118052482605\n",
      "tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0])\n",
      "epoch: 1 total_correct: 377 loss: 5.049574553966522\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0])\n",
      "epoch: 2 total_correct: 367 loss: 4.837797284126282\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 3 total_correct: 380 loss: 4.831047773361206\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 4 total_correct: 402 loss: 4.776127099990845\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 5 total_correct: 402 loss: 4.755714178085327\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1])\n",
      "epoch: 6 total_correct: 402 loss: 4.750090062618256\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0])\n",
      "epoch: 7 total_correct: 402 loss: 4.743481457233429\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0])\n",
      "epoch: 8 total_correct: 402 loss: 4.756978929042816\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 9 total_correct: 402 loss: 4.727366328239441\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1])\n",
      "epoch: 10 total_correct: 402 loss: 4.737209796905518\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1])\n",
      "epoch: 11 total_correct: 402 loss: 4.7354084849357605\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0])\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1])\n",
      "epoch: 12 total_correct: 402 loss: 4.725397884845734\n",
      "tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0])\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1])\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0])\n",
      "epoch: 13 total_correct: 402 loss: 4.765900194644928\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0])\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 14 total_correct: 402 loss: 4.734219908714294\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 15 total_correct: 402 loss: 4.714304745197296\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 16 total_correct: 402 loss: 4.715531706809998\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 17 total_correct: 402 loss: 4.720494389533997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18824/990829276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtotal_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18824/150617039.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py\u001b[0m in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model = Model().to(device)\n",
    "train_loader = torch.utils.data.DataLoader(training_data,batch_size = 100, shuffle = True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "writer = SummaryWriter('runs/numberplate_experiment_2')\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        print(labels)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss+= loss.item()\n",
    "        total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    add_scalars(total_loss, total_correct, training_data, epoch)\n",
    "    writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    writer.add_scalar(\"Accuracy\", total_correct/ len(training_data), epoch)\n",
    "    \n",
    "    writer.add_histogram(\"conv1.bias\", model.conv1.bias, epoch)\n",
    "    writer.add_histogram(\"conv1.weight\", model.conv1.weight, epoch)\n",
    "    writer.add_histogram(\"conv2.bias\", model.conv2.bias, epoch)\n",
    "    writer.add_histogram(\"conv2.weight\", model.conv2.weight, epoch)\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 1\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 316 loss: 27.24612295627594\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 376 loss: 15.49423462152481\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 402 loss: 14.988932490348816\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 376 loss: 15.093316674232483\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 402 loss: 14.973612427711487\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 5 total_correct: 362 loss: 14.885686248540878\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 6 total_correct: 402 loss: 15.269991248846054\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 7 total_correct: 362 loss: 15.692752033472061\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 15.37368756532669\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 9 total_correct: 402 loss: 14.93518751859665\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 14.8727308511734\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 14.906694173812866\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 14.855312943458557\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 14.824025273323059\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 14.836636453866959\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 15.072705149650574\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 15.110590398311615\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 15.17437595129013\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 15.08430302143097\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 15.102617740631104\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 15.037013232707977\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 21 total_correct: 381 loss: 14.729723185300827\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 15.14874118566513\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 23 total_correct: 401 loss: 15.030439019203186\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 24 total_correct: 386 loss: 15.35188215970993\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 14.909622609615326\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 14.976745903491974\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 14.837748944759369\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 15.025039374828339\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 14.980768501758575\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 14.94979453086853\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 14.822648644447327\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 14.73821097612381\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 14.908477008342743\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 15.017691552639008\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 15.062127113342285\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 14.969803094863892\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 15.00972467660904\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 38 total_correct: 357 loss: 15.310273468494415\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 39 total_correct: 402 loss: 14.74041998386383\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 15.153402924537659\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 14.86565774679184\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 15.008902072906494\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 43 total_correct: 322 loss: 15.260993242263794\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 44 total_correct: 402 loss: 14.89528203010559\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 45 total_correct: 402 loss: 14.878711581230164\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 46 total_correct: 402 loss: 15.01843374967575\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 47 total_correct: 402 loss: 14.783277094364166\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 48 total_correct: 402 loss: 14.929664492607117\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 49 total_correct: 402 loss: 14.844818830490112\n",
      "__________________________________________________________\n",
      "run id: 2\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 335 loss: 25.826999127864838\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 385 loss: 14.960508346557617\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 335 loss: 15.524790287017822\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 347 loss: 15.401816189289093\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 402 loss: 15.23347681760788\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 5 total_correct: 402 loss: 15.062700390815735\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 6 total_correct: 402 loss: 15.06289917230606\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 7 total_correct: 402 loss: 15.080287218093872\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 8 total_correct: 384 loss: 15.129623532295227\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 15.10146015882492\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 15.056542158126831\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 15.021176099777222\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 15.026665091514587\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 15.017257332801819\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 15.031144082546234\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 15.014159977436066\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 14.992428243160248\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 14.981804847717285\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 14.97577452659607\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 14.967214167118073\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 14.978069365024567\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 21 total_correct: 388 loss: 14.931118667125702\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 15.050932109355927\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 14.99041086435318\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 14.914150416851044\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 14.919866025447845\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 14.91507750749588\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 14.917996346950531\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 14.907471477985382\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 14.911332190036774\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 14.963963150978088\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 14.936464309692383\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 14.900318801403046\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 14.945954144001007\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 14.84867811203003\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 14.76155573129654\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 14.970159709453583\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 14.803205907344818\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 38 total_correct: 397 loss: 14.907088458538055\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 39 total_correct: 404 loss: 14.798206627368927\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 40 total_correct: 409 loss: 14.822499215602875\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 41 total_correct: 406 loss: 14.592649459838867\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 14.692562729120255\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 43 total_correct: 391 loss: 14.74013078212738\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 15.030935049057007\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 45 total_correct: 403 loss: 14.732714891433716\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 46 total_correct: 406 loss: 14.450595825910568\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 47 total_correct: 409 loss: 14.503732979297638\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 48 total_correct: 405 loss: 14.222720086574554\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 49 total_correct: 396 loss: 14.314313560724258\n",
      "__________________________________________________________\n",
      "run id: 3\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 337 loss: 20.36778074502945\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 393 loss: 8.7060986161232\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 329 loss: 7.784493982791901\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 402 loss: 7.537417352199554\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 402 loss: 7.444059371948242\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 5 total_correct: 402 loss: 7.410155415534973\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 6 total_correct: 402 loss: 7.453758597373962\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 7 total_correct: 402 loss: 7.437232255935669\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 7.458528459072113\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 9 total_correct: 402 loss: 7.427822291851044\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 7.408006548881531\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 7.428192615509033\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 7.468830227851868\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 7.399776995182037\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 7.477014660835266\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 7.621559202671051\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 7.481354713439941\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 7.497084021568298\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 7.417631566524506\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 7.418964266777039\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 7.406615734100342\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 7.439615845680237\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 7.406821608543396\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 7.420716166496277\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 7.40760999917984\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 7.394736111164093\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 7.4141541719436646\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 7.583782851696014\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 7.447692811489105\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 7.478568077087402\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 7.4197699427604675\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 7.435906708240509\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 7.46692031621933\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 7.48918616771698\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 7.479864001274109\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 7.396008133888245\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 7.42534738779068\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 7.434032738208771\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 38 total_correct: 370 loss: 7.547880589962006\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 39 total_correct: 402 loss: 7.5384403467178345\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 7.406643509864807\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 7.362858295440674\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 7.3703333735466\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 43 total_correct: 400 loss: 7.488215446472168\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 44 total_correct: 402 loss: 7.375856578350067\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 45 total_correct: 402 loss: 7.29295814037323\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 46 total_correct: 402 loss: 7.275361955165863\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 47 total_correct: 402 loss: 7.195013344287872\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 48 total_correct: 410 loss: 7.214727103710175\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 49 total_correct: 416 loss: 7.246087074279785\n",
      "__________________________________________________________\n",
      "run id: 4\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 269 loss: 26.199304461479187\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 402 loss: 9.18531721830368\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 312 loss: 8.03967171907425\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 402 loss: 7.438082993030548\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 402 loss: 7.519506633281708\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 5 total_correct: 402 loss: 7.421062529087067\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 6 total_correct: 402 loss: 7.443255424499512\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 7 total_correct: 402 loss: 7.431983709335327\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 8 total_correct: 402 loss: 7.433722972869873\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 7.431460022926331\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 7.43273264169693\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 7.428372442722321\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 7.426719427108765\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 7.421650290489197\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 7.414461851119995\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 15 total_correct: 400 loss: 7.4076828956604\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 16 total_correct: 400 loss: 7.404062390327454\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 17 total_correct: 399 loss: 7.394438803195953\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 18 total_correct: 398 loss: 7.392694652080536\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 19 total_correct: 400 loss: 7.376488208770752\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 20 total_correct: 404 loss: 7.335907697677612\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 21 total_correct: 406 loss: 7.313526928424835\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 22 total_correct: 406 loss: 7.2640188336372375\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 23 total_correct: 416 loss: 7.203446388244629\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 24 total_correct: 421 loss: 7.196692645549774\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 25 total_correct: 419 loss: 7.124206006526947\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 26 total_correct: 420 loss: 7.064876914024353\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 27 total_correct: 436 loss: 6.914196133613586\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 28 total_correct: 446 loss: 6.792410522699356\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 29 total_correct: 444 loss: 6.635895788669586\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 30 total_correct: 462 loss: 6.57894903421402\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 31 total_correct: 468 loss: 6.403050392866135\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 32 total_correct: 485 loss: 6.129487484693527\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 33 total_correct: 484 loss: 6.090818524360657\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 34 total_correct: 454 loss: 6.685883045196533\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 35 total_correct: 458 loss: 6.575327515602112\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 36 total_correct: 489 loss: 6.2346594631671906\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 37 total_correct: 491 loss: 6.012819200754166\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 38 total_correct: 491 loss: 5.951168984174728\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 39 total_correct: 499 loss: 5.855681359767914\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 40 total_correct: 530 loss: 5.107487171888351\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 41 total_correct: 522 loss: 5.202918589115143\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 42 total_correct: 524 loss: 5.081996709108353\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 43 total_correct: 531 loss: 4.996278941631317\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 44 total_correct: 552 loss: 4.769852697849274\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 45 total_correct: 525 loss: 5.214114427566528\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 46 total_correct: 554 loss: 4.459910467267036\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 47 total_correct: 554 loss: 4.213957816362381\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 48 total_correct: 560 loss: 4.149637117981911\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 49 total_correct: 544 loss: 4.583075076341629\n",
      "__________________________________________________________\n",
      "run id: 5\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 253 loss: 13.918532490730286\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 281 loss: 6.070934176445007\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 321 loss: 4.4239848256111145\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 368 loss: 4.318813741207123\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 396 loss: 4.262546360492706\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 5 total_correct: 383 loss: 4.237453401088715\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 6 total_correct: 360 loss: 4.117456674575806\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 7 total_correct: 402 loss: 4.063951253890991\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 4.051453709602356\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 9 total_correct: 402 loss: 4.070101737976074\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 4.096015632152557\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 4.066549301147461\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 4.048374056816101\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 4.066757440567017\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 4.044555604457855\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 4.032756745815277\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 4.010602712631226\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 4.06311297416687\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 4.03149151802063\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 4.036072015762329\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 4.048075556755066\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 4.051516115665436\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 4.0552502274513245\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 4.024989128112793\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 4.045257389545441\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 4.060944497585297\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 4.039011657238007\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 4.06302535533905\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 4.118335068225861\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 4.049633622169495\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 4.099015831947327\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 4.05379855632782\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 4.039618730545044\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 4.043093502521515\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 4.049146234989166\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 4.0718899965286255\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 4.051302790641785\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 4.0431042313575745\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 38 total_correct: 402 loss: 4.014308154582977\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 39 total_correct: 402 loss: 4.062382876873016\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 4.034486711025238\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 4.131460905075073\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 4.083466649055481\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 43 total_correct: 402 loss: 4.077364802360535\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 44 total_correct: 402 loss: 4.0538270473480225\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 45 total_correct: 402 loss: 4.049529075622559\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 46 total_correct: 402 loss: 4.117266237735748\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 47 total_correct: 402 loss: 4.070330619812012\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 48 total_correct: 402 loss: 4.11333554983139\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 49 total_correct: 402 loss: 4.043218433856964\n",
      "__________________________________________________________\n",
      "run id: 6\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 285 loss: 15.378151178359985\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 402 loss: 8.280086815357208\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 402 loss: 4.426855683326721\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 336 loss: 4.167259156703949\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 395 loss: 4.2057042717933655\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 5 total_correct: 361 loss: 4.221942484378815\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 6 total_correct: 352 loss: 4.344079971313477\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 7 total_correct: 331 loss: 4.3802565932273865\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 8 total_correct: 402 loss: 4.180192649364471\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 4.0587278008461\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 4.06889009475708\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 4.063788175582886\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 4.039849162101746\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 4.0500282645225525\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 4.050284922122955\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 4.042554259300232\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 4.043932557106018\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 4.04578173160553\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 4.042967855930328\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 4.042142868041992\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 4.043067395687103\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 4.041925072669983\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 4.041022956371307\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 4.040934085845947\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 4.040439128875732\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 4.039651870727539\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 4.039155602455139\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 4.038696110248566\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 4.037831246852875\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 4.03720623254776\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 4.036539912223816\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 4.03572404384613\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 4.034900724887848\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 4.0342718958854675\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 4.033294856548309\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 4.032505035400391\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 4.031794250011444\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 4.0309388637542725\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 4.030059993267059\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 4.029428780078888\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 40 total_correct: 402 loss: 4.028558671474457\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 41 total_correct: 402 loss: 4.027732253074646\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 4.027082800865173\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 43 total_correct: 402 loss: 4.02634197473526\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 4.025429666042328\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 4.024692714214325\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 46 total_correct: 402 loss: 4.0238834619522095\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 47 total_correct: 402 loss: 4.023183584213257\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 4.022334575653076\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 49 total_correct: 402 loss: 4.02165299654007\n",
      "__________________________________________________________\n",
      "run id: 7\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 249 loss: 69.694366812706\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 342 loss: 17.309981048107147\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 377 loss: 15.52591323852539\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 373 loss: 15.14270967245102\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 388 loss: 15.22866666316986\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 5 total_correct: 370 loss: 16.061803460121155\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 6 total_correct: 348 loss: 15.89016205072403\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 7 total_correct: 389 loss: 15.339850068092346\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 14.668804854154587\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 9 total_correct: 359 loss: 15.595705687999725\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 14.849358886480331\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 11 total_correct: 368 loss: 15.523078799247742\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 15.312410116195679\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 14.655120313167572\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 14 total_correct: 357 loss: 15.81518417596817\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 15.059477686882019\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 16 total_correct: 362 loss: 15.026156783103943\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 14.720461010932922\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 15.067691266536713\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 15.006487905979156\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 14.824636936187744\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 14.876446187496185\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 15.019905388355255\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 15.061275720596313\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 14.889180123806\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 15.014958322048187\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 26 total_correct: 387 loss: 14.844173938035965\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 14.904468834400177\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 15.144058346748352\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 15.0471510887146\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 14.811680555343628\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 14.839136362075806\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 14.89994502067566\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 33 total_correct: 403 loss: 14.846647441387177\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 14.648885130882263\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 14.801186621189117\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 36 total_correct: 404 loss: 14.872835278511047\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 14.721978068351746\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 38 total_correct: 406 loss: 14.834915816783905\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 39 total_correct: 403 loss: 14.936002790927887\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 14.855540871620178\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 41 total_correct: 405 loss: 14.632680892944336\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 42 total_correct: 392 loss: 14.874985158443451\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 43 total_correct: 399 loss: 14.782150387763977\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 44 total_correct: 415 loss: 14.820254802703857\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 45 total_correct: 400 loss: 14.832248151302338\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 46 total_correct: 403 loss: 14.71011769771576\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 47 total_correct: 405 loss: 14.66773772239685\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 48 total_correct: 400 loss: 14.736539125442505\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 49 total_correct: 405 loss: 14.710098683834076\n",
      "__________________________________________________________\n",
      "run id: 8\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 291 loss: 66.15405797958374\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 350 loss: 16.388161838054657\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 362 loss: 16.829337775707245\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 408 loss: 14.863054394721985\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 396 loss: 15.068186223506927\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 5 total_correct: 376 loss: 15.152037262916565\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 6 total_correct: 372 loss: 15.147315323352814\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 7 total_correct: 368 loss: 15.151414096355438\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 8 total_correct: 363 loss: 15.168522238731384\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 9 total_correct: 367 loss: 15.171499073505402\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 10 total_correct: 385 loss: 15.167797088623047\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 15.1573925614357\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 15.102912962436676\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 15.068946719169617\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 15.050921142101288\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 15.039245784282684\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 15.028187692165375\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 15.02045089006424\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 15.01175719499588\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 15.005099356174469\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 15.001351356506348\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 14.995350539684296\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 14.98893517255783\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 14.981491446495056\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 14.982640266418457\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 14.973549544811249\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 14.963400065898895\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 14.956632494926453\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 14.950651466846466\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 14.943256497383118\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 14.936256647109985\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 14.92958652973175\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 14.924605548381805\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 14.91793966293335\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 14.909663319587708\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 14.901560842990875\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 14.890824615955353\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 14.87983787059784\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 14.86833119392395\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 14.856213510036469\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 40 total_correct: 403 loss: 14.841430127620697\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 41 total_correct: 405 loss: 14.824855387210846\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 42 total_correct: 405 loss: 14.80804967880249\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 43 total_correct: 405 loss: 14.787438094615936\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 44 total_correct: 404 loss: 14.764843046665192\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 14.740410208702087\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 46 total_correct: 400 loss: 14.716599375009537\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 47 total_correct: 403 loss: 14.686160385608673\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 14.654077976942062\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 49 total_correct: 399 loss: 14.615846186876297\n",
      "__________________________________________________________\n",
      "run id: 9\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 164 loss: 43.363471269607544\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 402 loss: 26.295618891716003\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 347 loss: 9.459377467632294\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 401 loss: 7.885217130184174\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 358 loss: 7.964924693107605\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 5 total_correct: 374 loss: 7.580193817615509\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 6 total_correct: 403 loss: 7.485031604766846\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 7 total_correct: 402 loss: 7.604471921920776\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 7.595073699951172\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 9 total_correct: 342 loss: 7.678823411464691\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 7.585114896297455\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 7.518393516540527\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 7.554508924484253\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 13 total_correct: 403 loss: 7.525681793689728\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 7.484487593173981\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 7.472942113876343\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 7.44753897190094\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 7.414145112037659\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 7.480726182460785\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 7.455009937286377\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 7.472830593585968\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 7.450009763240814\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 7.482929468154907\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 7.435028672218323\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 7.449386477470398\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 7.474413752555847\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 7.417469143867493\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 7.400317430496216\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 7.419285356998444\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 7.4387858510017395\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 7.476082384586334\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 7.390245079994202\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 7.49998539686203\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 7.435087621212006\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 7.423947334289551\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 7.4363632798194885\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 7.40404212474823\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 7.395208716392517\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 38 total_correct: 402 loss: 7.424441993236542\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 39 total_correct: 404 loss: 7.513106822967529\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 7.3528507351875305\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 7.373942792415619\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 42 total_correct: 403 loss: 7.379277527332306\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 43 total_correct: 404 loss: 7.466032445430756\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 44 total_correct: 404 loss: 7.293300747871399\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 45 total_correct: 405 loss: 7.335013687610626\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 46 total_correct: 410 loss: 7.275436520576477\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 47 total_correct: 406 loss: 7.21469783782959\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 48 total_correct: 405 loss: 7.2302141189575195\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 49 total_correct: 392 loss: 7.31055074930191\n",
      "__________________________________________________________\n",
      "run id: 10\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 116 loss: 43.830933570861816\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 410 loss: 20.264520347118378\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 359 loss: 8.498886585235596\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 408 loss: 7.465622246265411\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 356 loss: 8.032836318016052\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 5 total_correct: 407 loss: 7.480553388595581\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 6 total_correct: 387 loss: 7.647056579589844\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 7 total_correct: 402 loss: 7.573605477809906\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 8 total_correct: 400 loss: 7.530215203762054\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 9 total_correct: 401 loss: 7.555724322795868\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 7.568820774555206\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 11 total_correct: 389 loss: 7.583356022834778\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 12 total_correct: 385 loss: 7.6292884349823\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 13 total_correct: 365 loss: 7.722759008407593\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 14 total_correct: 344 loss: 7.822085678577423\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 15 total_correct: 351 loss: 7.869375109672546\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 7.724709331989288\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 7.5004711747169495\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 18 total_correct: 403 loss: 7.549408316612244\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 19 total_correct: 403 loss: 7.589342772960663\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 20 total_correct: 403 loss: 7.58121383190155\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 7.571530640125275\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 7.568197667598724\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 23 total_correct: 403 loss: 7.561914086341858\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 24 total_correct: 403 loss: 7.55134654045105\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 25 total_correct: 403 loss: 7.541622161865234\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 26 total_correct: 403 loss: 7.536372363567352\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 27 total_correct: 403 loss: 7.531864106655121\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 7.526395320892334\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 7.5204116106033325\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 7.513915240764618\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 7.507997274398804\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 7.502902388572693\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 7.497766077518463\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 7.492101788520813\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 7.486887156963348\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 7.482308566570282\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 7.47810685634613\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 7.47372043132782\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 7.4693310260772705\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 40 total_correct: 402 loss: 7.464672803878784\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 41 total_correct: 402 loss: 7.460358917713165\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 7.455932378768921\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 43 total_correct: 402 loss: 7.4517799615859985\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 7.447810411453247\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 7.443659663200378\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 46 total_correct: 402 loss: 7.438999891281128\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 47 total_correct: 402 loss: 7.4352598786354065\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 7.431049704551697\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 49 total_correct: 402 loss: 7.426621675491333\n",
      "__________________________________________________________\n",
      "run id: 11\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 114 loss: 23.96440625190735\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 402 loss: 19.72678828239441\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 402 loss: 8.527487516403198\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 347 loss: 4.35051167011261\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 356 loss: 4.174541115760803\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 5 total_correct: 397 loss: 4.085350811481476\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 6 total_correct: 358 loss: 4.229199230670929\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 7 total_correct: 383 loss: 4.141476333141327\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 8 total_correct: 378 loss: 4.1829657554626465\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 9 total_correct: 370 loss: 4.117190062999725\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 10 total_correct: 353 loss: 4.1802122592926025\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 11 total_correct: 374 loss: 4.252385854721069\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 12 total_correct: 373 loss: 4.123814046382904\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 13 total_correct: 376 loss: 4.044641077518463\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 14 total_correct: 369 loss: 4.252564489841461\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 15 total_correct: 391 loss: 4.196823239326477\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 16 total_correct: 400 loss: 4.057255148887634\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 17 total_correct: 403 loss: 4.036999702453613\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 4.101633846759796\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 19 total_correct: 341 loss: 4.099148869514465\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 20 total_correct: 363 loss: 4.206672370433807\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 21 total_correct: 388 loss: 4.184188544750214\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 22 total_correct: 401 loss: 4.026743233203888\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 23 total_correct: 401 loss: 4.088083565235138\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 4.060262084007263\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 4.032184183597565\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 4.052981734275818\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 4.0298378467559814\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 4.085800647735596\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 4.082065641880035\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 4.0641807317733765\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 4.105561673641205\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 4.04161673784256\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 4.028831958770752\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 4.03004777431488\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 4.032059371471405\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 4.205872476100922\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 37 total_correct: 388 loss: 4.073063433170319\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 38 total_correct: 403 loss: 4.057521104812622\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 39 total_correct: 375 loss: 4.148207247257233\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 40 total_correct: 403 loss: 4.042802572250366\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 41 total_correct: 401 loss: 4.049214780330658\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 3.9951016902923584\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 43 total_correct: 403 loss: 4.040547549724579\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 44 total_correct: 401 loss: 4.093116462230682\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 45 total_correct: 401 loss: 4.061325430870056\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 46 total_correct: 403 loss: 4.065863609313965\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 47 total_correct: 403 loss: 4.106115758419037\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 48 total_correct: 405 loss: 4.019805908203125\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 49 total_correct: 403 loss: 4.023688852787018\n",
      "__________________________________________________________\n",
      "run id: 12\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 0 loss: 24.674416065216064\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 349 loss: 23.268605947494507\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 402 loss: 17.18660569190979\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 402 loss: 7.63860958814621\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 335 loss: 5.04662024974823\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 5 total_correct: 381 loss: 4.314918398857117\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 6 total_correct: 360 loss: 4.425480008125305\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 7 total_correct: 380 loss: 4.103124618530273\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 8 total_correct: 402 loss: 4.20444792509079\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 4.071534991264343\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 4.12193638086319\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 4.0686914920806885\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 4.089491546154022\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 4.0675570368766785\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 4.077975213527679\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 4.065901100635529\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 4.074319779872894\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 4.064665973186493\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 4.072988152503967\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 4.064190030097961\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 4.0716217160224915\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 4.064895749092102\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 4.069674491882324\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 4.065991699695587\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 4.067696034908295\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 4.066888391971588\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 4.066313683986664\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 4.066775143146515\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 4.065880179405212\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 4.06610381603241\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 4.065442204475403\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 4.065295577049255\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 4.064584136009216\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 4.064287304878235\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 4.063662350177765\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 4.063196539878845\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 4.062453269958496\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 4.061942458152771\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 4.06119704246521\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 4.060689866542816\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 40 total_correct: 402 loss: 4.060076117515564\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 41 total_correct: 402 loss: 4.059165179729462\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 4.058498740196228\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 43 total_correct: 402 loss: 4.0577919483184814\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 4.056876540184021\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 4.05630087852478\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 46 total_correct: 402 loss: 4.055235803127289\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 47 total_correct: 402 loss: 4.0546072125434875\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 4.05353844165802\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 49 total_correct: 402 loss: 4.052730083465576\n",
      "__________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "parameters = dict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [32,64,128],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "\n",
    "for run_id, (lr,batch_size, shuffle) in enumerate(product(*param_values)):\n",
    "    print(\"run id:\", run_id + 1)\n",
    "    model = Model().to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(training_data,batch_size = batch_size, shuffle = shuffle)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    comment = f' batch_size = {batch_size} lr = {lr} shuffle = {shuffle}'\n",
    "    writer = SummaryWriter('runs/numberplate_experiment_3',comment=comment)\n",
    "    for epoch in range(50):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "            total_loss+= loss.item()\n",
    "            total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        add_scalars(total_loss, total_correct, training_data, epoch)\n",
    "        writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        writer.add_scalar(\"Accuracy\", total_correct/ len(training_data), epoch)\n",
    "\n",
    "        print(\"batch_size:\",batch_size, \"lr:\",lr,\"shuffle:\",shuffle)\n",
    "        print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "    print(\"__________________________________________________________\")\n",
    "\n",
    "    writer.add_hparams(\n",
    "            {\"lr\": lr, \"bsize\": batch_size, \"shuffle\":shuffle},\n",
    "            {\n",
    "                \"accuracy\": total_correct/ len(training_data),\n",
    "                \"loss\": total_loss,\n",
    "            },\n",
    "        )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 4 - OPGAVE 1\n",
    "'''\n",
    "imageData = read_image_data()\n",
    "\n",
    "os.makedirs('MaskedNumberplates', exist_ok=True)\n",
    "\n",
    "for id in imageData:\n",
    "    im = Image.open(imagepath + id.path)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.rectangle([id.xmin,id.ymin, id.xmax,id.ymax], fill=True)\n",
    "\n",
    "    #im = im.( (id.xmin, id.ymin, id.xmax, id.ymax) )\n",
    "    im.save('MaskedNumberplates/' + id.path) \n",
    "    im.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(bb, x):\n",
    "    \"\"\"Creates a mask for the bounding box of same shape as image\"\"\"\n",
    "    rows,cols,*_ = x.shape\n",
    "    Y = np.zeros((rows, cols))\n",
    "    bb = bb.astype(np.int)\n",
    "    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n",
    "    return Y\n",
    "\n",
    "def mask_to_bb(Y):\n",
    "    \"\"\"Convert mask Y to a bounding box, assumes 0 as background nonzero object\"\"\"\n",
    "    cols, rows = np.nonzero(Y)\n",
    "    if len(cols)==0: \n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    top_row = np.min(rows)\n",
    "    left_col = np.min(cols)\n",
    "    bottom_row = np.max(rows)\n",
    "    right_col = np.max(cols)\n",
    "    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n",
    "\n",
    "def create_bb_array(x):\n",
    "    \"\"\"Generates bounding box array from a train_df row\"\"\"\n",
    "    return np.array([x[5],x[4],x[7],x[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_bb(read_path,write_path,bb,sz):\n",
    "    \"\"\"Resize an image and its bounding box and write image to new path\"\"\"\n",
    "    im = read_image(read_path)\n",
    "    im_resized = cv2.resize(im, (int(1.49*sz), sz))\n",
    "    Y_resized = cv2.resize(create_mask(bb, im), (int(1.49*sz), sz))\n",
    "    new_path = str(write_path/read_path.parts[-1])\n",
    "    cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n",
    "    return new_path, mask_to_bb(Y_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
