{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import csv\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "imagepath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "csvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "croppedImagesPath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "trainingdatacsvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/trainingdata.csv'\n",
    "predictioncsvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n",
    "\n",
    "#imagepath = 'C:/Users/chris/source/repos//DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "#csvpath = 'C:/Users//chris//source/repos//DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "#croppedImagesPath = 'C:/Users//chris//source/repos//DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "#trainingdatacsvpath = 'C:/Users/chris/source/repos//DeepLearning/DatasætDeeplearning/trainingdata.csv'\n",
    "#predictioncsvpath = 'C:/Users//chris/source/repos//DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opgave 1\n",
    "class ImageData:\n",
    "    def __init__(self, path, ymin, xmin, ymax, xmax):\n",
    "        self.path = path\n",
    "        self.xmin = xmin      \n",
    "        self.ymin = ymin        \n",
    "        self.xmax = xmax        \n",
    "        self.ymax = ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data():\n",
    "    file = open(csvpath)\n",
    "    csvreader = csv.reader(file)\n",
    "    rows = []\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "            id = ImageData(row[0], int(row[1]), int(row[2]), int(row[3]), int(row[4]))\n",
    "            rows.append(id)\n",
    "    file.close()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(croppedImagesPath, exist_ok=True)\n",
    "\n",
    "def crop_images():\n",
    "    imageData = read_image_data()\n",
    "\n",
    "    for id in imageData:\n",
    "        im = Image.open(imagepath + id.path)\n",
    "        im = im.crop( (id.xmin, id.ymin, id.xmax, id.ymax) )\n",
    "        im.save(croppedImagesPath + id.path) \n",
    "        im.close()\n",
    "\n",
    "crop_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opgave 2\n",
    "class PredictionData:\n",
    "    def __init__(self, path, licenseplate):\n",
    "        self.path = path\n",
    "        self.licenseplate = licenseplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prediction_data():\n",
    "    file = open(predictioncsvpath)\n",
    "    csvreader = csv.reader(file)\n",
    "    rows = []\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "            pd = PredictionData(row[0], row[1])\n",
    "            rows.append(pd)\n",
    "    file.close()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoding():\n",
    "    predictiondata = read_prediction_data()\n",
    "    numbers = '0123456789'\n",
    "    onehot_encoded = list()\n",
    "    header = ['img_id', 'text', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "    with open(trainingdatacsvpath, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "       \n",
    "\n",
    "        for data in predictiondata:\n",
    "            # Removes T and N from licenseplate\n",
    "            datatrimmed = data.licenseplate.replace('T', '')\n",
    "            datatrimmed = datatrimmed.replace('N', '')\n",
    "\n",
    "            char_to_int = dict((c, i) for i, c in enumerate(numbers))\n",
    "            # integer encode input data\n",
    "            integer_encoded = [char_to_int[char] for char in datatrimmed]\n",
    "            #print(integer_encoded)\n",
    "            # one hot encode\n",
    "            letter = [0 for _ in range(len(numbers))]\n",
    "            for value in integer_encoded:\n",
    "                letter[value] = 1\n",
    "            \n",
    "            letter.insert(0, data.path)\n",
    "            letter.insert(1, data.licenseplate)\n",
    "            writer.writerow(letter)\n",
    "            onehot_encoded.append(letter)\n",
    "\n",
    "onehot_encoding() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opgave 3\n",
    "with open(trainingdatacsvpath) as trainingcsv:\n",
    "    next(trainingcsv)\n",
    "    file_read = csv.reader(trainingcsv)\n",
    "    array = list(file_read)\n",
    "\n",
    "train, test = train_test_split(array,test_size=0.25,random_state=10) #Det unikke seed nummer er 10\n",
    "header = ['img_id', 'text', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "pd.DataFrame(test).to_csv(\"test.csv\",header=header,index=False)\n",
    "pd.DataFrame(train).to_csv(\"train.csv\",header=header,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (225, 12)\n",
      "CSV head:\n",
      "    img_id      text  0  1  2  3  4  5  6  7  8  9\n",
      "0  498.jpg  148T4932  0  1  1  1  1  0  0  0  1  1\n",
      "1  217.jpg  174T4999  0  1  0  0  1  0  0  1  0  1\n",
      "2  677.jpg  130T2637  1  1  1  1  0  0  1  1  0  0\n",
      "3  276.jpg  148T2903  1  1  1  1  1  0  0  0  1  1\n",
      "4  307.jpg  141T6603  1  1  0  1  1  0  1  0  0  0\n",
      "CSV tail:\n",
      "      img_id      text  0  1  2  3  4  5  6  7  8  9\n",
      "220  175.jpg  175T7944  0  1  0  0  1  1  0  1  0  1\n",
      "221  832.jpg   105T294  1  1  1  0  1  1  0  0  0  1\n",
      "222  703.jpg   89T4187  0  1  0  0  1  0  0  1  1  1\n",
      "223  764.jpg  156T4000  1  1  0  0  1  1  1  0  0  0\n",
      "224  395.jpg  189T8840  1  1  0  0  1  0  0  0  1  1\n"
     ]
    }
   ],
   "source": [
    "#Opgave 4\n",
    "def show_data_from_csv(csv_filepath: str):\n",
    "    csv_data = pd.read_csv(\"test.csv\")\n",
    "    print(\"CSV shape:\", csv_data.shape) \n",
    "    print(\"CSV head:\")\n",
    "    print(csv_data.head()) #det samme som csv_data[:5]\n",
    "    print(\"CSV tail:\")\n",
    "    print(csv_data.tail()) #det samme som csv_data[-5:]\n",
    "\n",
    "show_data_from_csv(\"test.csv\") #\"train.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(25),\n",
    "    transforms.CenterCrop(25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "imagenet_data = torchvision.datasets.ImageFolder(root=\"DatasætDeeplearning/\",transform=TRANSFORM_IMG)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(imagenet_data, batch_size=4,\n",
    "                                        shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=4,\n",
    "                                        shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel: #Der er kun en kanal\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5  #unnormalize, for at få den tilbage til den oprindelige til det neurale netværk (der kan godt udkommenteres)\n",
    "    npimg = img.numpy()\n",
    "    if one_channel: #Hvis der kun er en kanal blier det grå billeder \n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else: #Hvis der er flere kanaler bliver det favet billeder \n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=144, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10)#linear layer som har input features 84 og output feature 10. \n",
    "\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))#max pooling med en pooling shape på 2x2 over det første 2D convolutional layer\n",
    "        x = self.pool(F.relu(self.conv2(x)))#max pooling med en pooling shape på 2x2 over det andet 2D convolutional layer\n",
    "        x = x.view(-1, 9 * 4 * 4) #Ændrer formen på tensors.\n",
    "        x = F.relu(self.fc1(x))#Linear layer bliver aktiveret via activation function \n",
    "        x = F.relu(self.fc2(x))#Linear layer bliver aktiveret via activation function \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #Bliver brugt til classification Logits --> softmax --> out probabilities opdeling i classes\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/numberplate_experiment_1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader) #Opretter en iterator, hvor den tager trainloader som parameter\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "writer.add_graph(model, images) #Tilføjer grafdata, tager imode vores model (net) og modeldata (images), som pararmetre\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images) #Laver et grid af vores billeder iform af et tensor\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True) #Kalder vores funktion, som vi har defineret højere oppe i koden\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('numberplate_images', img_grid) #Data tilføjes til vores tensorborad\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3392), started 7 days, 0:33:29 ago. (Use '!kill 3392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ff5bffcece3794b7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ff5bffcece3794b7\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard \n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c72a629dba5ae9edebcad565c17c3988d814021371aabb3db62cb04d2b10dbfe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
