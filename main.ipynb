{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Vi importerer nødvendige biblioteker\n",
    "og definerer globale variabler med stinavne/filnavne \n",
    "'''\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.metrics import f1_score\n",
    "import argparse\n",
    "\n",
    "\n",
    "imagepath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "csvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "croppedImagesPath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "trainingdatacsvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/trainingdata.csv'\n",
    "predictioncsvpath = 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n",
    "testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "trainFolder = 'DatasætDeeplearning/TestImages/'\n",
    "\n",
    "#imagepath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "#csvpath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "#croppedImagesPath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "#trainingdatacsvpath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/trainingdata.csv'\n",
    "#predictioncsvpath = 'C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n",
    "#testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "#trainFolder = 'DatasætDeeplearning/TestImages/'\n",
    "\n",
    "\n",
    "# imagepath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/license_plates_detection_train/'\n",
    "# csvpath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/license_plates_detection_train.csv'\n",
    "# croppedImagesPath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/croppedImages/'\n",
    "# trainingdatacsvpath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/trainingdata.csv'\n",
    "# predictioncsvpath = 'C:/Users/chris/source/repos/DeepLearning/DatasætDeeplearning/license_plates_recognition_train.csv'\n",
    "# testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "# trainFolder = 'DatasætDeeplearning/TestImages/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - HELPER\n",
    "Vi definerer en klasse med billededata,\n",
    "som vi kan definere nye obkejter af\n",
    "'''\n",
    "class ImageData:\n",
    "    def __init__(self, path, ymin, xmin, ymax, xmax):\n",
    "        self.path = path\n",
    "        self.xmin = xmin      \n",
    "        self.ymin = ymin        \n",
    "        self.xmax = xmax        \n",
    "        self.ymax = ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - HELPER\n",
    "En funktion som læser data fra .CSV fil, \n",
    "og opretter nye billededata objekter af denne data\n",
    "(.CSV filen indeholder data om, hvor nummerpladen sidder (XY-koordinater))\n",
    "'''\n",
    "def read_image_data():\n",
    "    file = open(csvpath)\n",
    "    csvreader = csv.reader(file)\n",
    "    rows = []\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "            imgdt = ImageData(row[0], int(row[1]), int(row[2]), int(row[3]), int(row[4]))\n",
    "            rows.append(imgdt)\n",
    "    file.close()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 1\n",
    "En funktion som læser billederne ind, \n",
    "og klipper nummerpladen ud,\n",
    "hvorefter de nye billeder gemmes i en ny mappe (croppedImages)\n",
    "'''\n",
    "def crop_images():\n",
    "    imageData = read_image_data()\n",
    "\n",
    "    for id in imageData:\n",
    "        im = Image.open(imagepath + id.path)\n",
    "        im = im.crop( (id.xmin, id.ymin, id.xmax, id.ymax) )\n",
    "        im.save(croppedImagesPath + id.path) \n",
    "        im.close()\n",
    "\n",
    "os.makedirs(croppedImagesPath, exist_ok=True)\n",
    "\n",
    "crop_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 2 \n",
    "Vi definerer en klasse,\n",
    "som kun indeholder billedets navn (filnavn) og nummerpladen (string)\n",
    "'''\n",
    "class PredictionData:\n",
    "    def __init__(self, path, licenseplate):\n",
    "        self.path = path\n",
    "        self.licenseplate = licenseplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - HELPER \n",
    "En funktion som læser data fra .CSV filen,\n",
    "og opretter nye objekter af PredictionData\n",
    "'''\n",
    "def read_prediction_data():\n",
    "    file = open(predictioncsvpath)\n",
    "    csvreader = csv.reader(file)\n",
    "    rows = []\n",
    "    next(csvreader)\n",
    "    for row in csvreader:\n",
    "            pd = PredictionData(row[0], row[1])\n",
    "            rows.append(pd)\n",
    "    file.close()\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 2 \n",
    "En funktion som laver vores data om til one-hot-encoding, som gemmes i en ny .CSV fil.\n",
    "Vi behandler vores data, hvor one-hot-encoding deler vores data op i kategorier, \n",
    "som vores Deep learning algortime kan forstå.\n",
    "'''\n",
    "def onehot_encoding():\n",
    "    predictiondata = read_prediction_data()\n",
    "    numbers = '0123456789'\n",
    "    onehot_encoded = list()\n",
    "    #header = ['img_id', 'text', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    header = ['img_id', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "    with open(trainingdatacsvpath, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for data in predictiondata:\n",
    "            # Vi fjerner T and N fra nummerpladen\n",
    "            datatrimmed = data.licenseplate.replace('T', '')\n",
    "            datatrimmed = datatrimmed.replace('N', '')\n",
    "\n",
    "            # Vi laver nummerpladen om til en liste af nummerene fra nummerpladen\n",
    "            char_to_int = dict((c, i) for i, c in enumerate(numbers))\n",
    "            integer_encoded = [char_to_int[char] for char in datatrimmed] \n",
    "            #print(integer_encoded)\n",
    "\n",
    "            # Vi laver nu one-hot-encode\n",
    "            # 1 bliver sat, hvis det eksisterer i nummerpladen\n",
    "            letter = [0 for _ in range(len(numbers))]\n",
    "            for value in integer_encoded:\n",
    "                letter[value] = 1\n",
    "            \n",
    "            # Billedets navn og den oprindelige nummerplade indsættes også i vores .CSV fil\n",
    "            letter.insert(0, data.path)\n",
    "            #letter.insert(1, data.licenseplate)\n",
    "            \n",
    "            writer.writerow(letter)\n",
    "            onehot_encoded.append(letter)\n",
    "\n",
    "onehot_encoding() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 3 \n",
    "Vi opdeler i et training set og et validation set,\n",
    "hvor vi angiver et seed, hvilket sikre at samme datasæt generes ved samme seed\n",
    "'''\n",
    "with open(trainingdatacsvpath) as trainingcsv:\n",
    "    next(trainingcsv)\n",
    "    file_read = csv.reader(trainingcsv)\n",
    "    array = list(file_read)\n",
    "\n",
    "train, test = train_test_split(array,test_size=0.25,random_state=10) #Det unikke seed nummer er 10\n",
    "#header = ['img_id', 'text', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "header = ['img_id', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# Vi tilføjer headers til vores data, tilføjer den til to nye .CSV filer\n",
    "pd.DataFrame(test).to_csv(\"test.csv\",header=header,index=False)\n",
    "pd.DataFrame(train).to_csv(\"train.csv\",header=header,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFolder = 'DatasætDeeplearning/TestImages/'\n",
    "trainFolder = 'DatasætDeeplearning/TrainImages/'\n",
    "\n",
    "os.makedirs(testFolder, exist_ok=True)\n",
    "os.makedirs(trainFolder, exist_ok=True)\n",
    "\n",
    "files = glob.glob(testFolder + '*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = glob.glob(trainFolder + '*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "for img in test:\n",
    "   shutil.copy('C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    " + img[0], testFolder + img[0])\n",
    "\n",
    "for img in train:\n",
    "   shutil.copy('C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    " + img[0], trainFolder + img[0])\n",
    "\n",
    "# for img in test:\n",
    "#     shutil.copy('C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], testFolder + img[0])\n",
    "\n",
    "# for img in train:\n",
    "#     shutil.copy('C:/Users/yusuf/Documents/GitHub/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], trainFolder + img[0])\n",
    "\n",
    "# for img in test:\n",
    "#    shutil.copy('C:/Users/chris/source/repos/DeepLearning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], testFolder + img[0])\n",
    "\n",
    "# for img in train:\n",
    "#    shutil.copy('C:/Users/chris/source/repos/DeepLearning/Eksamensprojekt/kode/DeepLearning/DatasætDeeplearning/license_plates_recognition_train/'\n",
    "#  + img[0], trainFolder + img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV shape: (225, 11)\n",
      "CSV head:\n",
      "    img_id  0  1  2  3  4  5  6  7  8  9\n",
      "0  498.jpg  0  1  1  1  1  0  0  0  1  1\n",
      "1  217.jpg  0  1  0  0  1  0  0  1  0  1\n",
      "2  677.jpg  1  1  1  1  0  0  1  1  0  0\n",
      "3  276.jpg  1  1  1  1  1  0  0  0  1  1\n",
      "4  307.jpg  1  1  0  1  1  0  1  0  0  0\n",
      "CSV tail:\n",
      "      img_id  0  1  2  3  4  5  6  7  8  9\n",
      "220  175.jpg  0  1  0  0  1  1  0  1  0  1\n",
      "221  832.jpg  1  1  1  0  1  1  0  0  0  1\n",
      "222  703.jpg  0  1  0  0  1  0  0  1  1  1\n",
      "223  764.jpg  1  1  0  0  1  1  1  0  0  0\n",
      "224  395.jpg  1  1  0  0  1  0  0  0  1  1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DEL 1 - OPGAVE 4 \n",
    "Vi laver en funktion, som kan visualisere vores data.\n",
    "Der printes: \n",
    "    - shape (rækker, koloner)\n",
    "    - head (de første 5 rækker)\n",
    "    - tail (de sidste 5 rækker)\n",
    "'''\n",
    "def show_data_from_csv(csv_filepath: str):\n",
    "    csv_data = pd.read_csv(\"test.csv\")\n",
    "    print(\"CSV shape:\", csv_data.shape) \n",
    "    print(\"CSV head:\")\n",
    "    print(csv_data.head()) #det samme som csv_data[:5]\n",
    "    print(\"CSV tail:\")\n",
    "    print(csv_data.tail()) #det samme som csv_data[-5:]\n",
    "\n",
    "show_data_from_csv(\"test.csv\") #\"train.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "En klasse som indeholder billededata fra .CSV fil\n",
    "'''\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1:11]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "5    1\n",
      "6    1\n",
      "7    0\n",
      "8    1\n",
      "9    0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "x = CustomImageDataset('train.csv', trainFolder)\n",
    "y, z = x.__getitem__(0)\n",
    "print(z) #0,1,0,1,0,1,1,0,1,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "Vi opretter en billedetransformer, hvor vi laver billederindstillingerne ens for alle billeder\n",
    "Derefter opretter vi to objekter af CustomImageDataset, \n",
    "som indeholder billededata, samt vores billedetransformer\n",
    "Til sidst definerer vi vores DataLoaders, som vi kan bruge til iterere henover\n",
    "'''\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(25),\n",
    "    transforms.CenterCrop(25),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(0.4915,0.4823,0.4468)\n",
    "])\n",
    "\n",
    "training_data = CustomImageDataset(\n",
    "    'train.csv', trainFolder, transform=TRANSFORM_IMG)\n",
    "\n",
    "test_data = CustomImageDataset(\n",
    "    'test.csv', testFolder, transform=TRANSFORM_IMG)\n",
    "\n",
    "trainloader = DataLoader(training_data, batch_size=10, shuffle=True) #, num_workers=2\n",
    "testloader = DataLoader(test_data, batch_size=64, shuffle=True) # , num_workers=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "En funktion som anvendes til at vise et billede\n",
    "'''\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel: #Der er kun en kanal\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5  #unnormalize, for at få den tilbage til den oprindelige til det neurale netværk (der kan godt udkommenteres)\n",
    "    npimg = img.numpy()\n",
    "    if one_channel: #Hvis der kun er en kanal blier det grå billeder \n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else: #Hvis der er flere kanaler bliver det favet billeder \n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 2 - OPGAVE 4 \n",
    "Dette er vores model klasse\n",
    "'''\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=144, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=60)#linear layer som har input features 84 og output feature 10. \n",
    "\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))#max pooling med en pooling shape på 2x2 over det første 2D convolutional layer\n",
    "        x = self.pool(F.relu(self.conv2(x)))#max pooling med en pooling shape på 2x2 over det andet 2D convolutional layer\n",
    "        x = x.view(-1, 9 * 4 * 4) #Ændrer formen på tensors.\n",
    "        x = F.relu(self.fc1(x))#Linear layer bliver aktiveret via activation function \n",
    "        x = F.relu(self.fc2(x))#Linear layer bliver aktiveret via activation function \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=128,\n",
    "shuffle=True)\n",
    "\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #Bliver brugt til classification Logits --> softmax --> out probabilities opdeling i classes\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/numberplate_experiment_1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader) #Opretter en iterator, hvor den tager trainloader som parameter\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "writer.add_graph(model, images) #Tilføjer grafdata, tager imod vores model og modeldata (images), som pararmetre\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images) #Laver et grid af vores billeder iform af et tensor\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True) #Kalder vores funktion, som vi har defineret højere oppe i koden\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('numberplate_images', img_grid) #Data tilføjes til vores tensorborad\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scalars(total_loss, total_correct, train_set, epoch):\n",
    "    writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    writer.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images): \n",
    "    '''\n",
    "    Genererer forudsigelser og tilsvarende sandsynligheder fra en trænet\n",
    "     netværk og en liste over billeder\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # konvertere output sandsynligheder til forudsagt klasse\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy()) #Fjerner enkeltdimensionelle indgange fra formen af et array\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "    # softmax konverterer en vektor af tal til en vektor af sandsynligheder, hvor sandsynligheden for hver værdi er proportional med den relative skala af hver værdi i vektoren. \n",
    "    #Zip()-funktionen tager iterables (kan være nul eller flere), samler dem i en tupel og returnerer den\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Genererer matplotlib-figur ved hjælp af et trænet netværk sammen med billeder\n",
    "     og etiketter fra en batch, der viser netværkets bedste forudsigelse\n",
    "     med dens sandsynlighed, sammen med den faktiske etiket, farve denne\n",
    "     information baseret på, om forudsigelsen var korrekt eller ej.\n",
    "     Bruger funktionen \"images_to_probs\".\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot billederne i batchen sammen med forudsagte og sande etiketter\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%/n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "                    #Den sammenligner sandsynligheden med billederne og labels \n",
    "                    #grøn jo mere sandsynlig den er og rød hvis den er mindre sandsynlig kan ses når vi køre koden\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6001 (pid 6788), started 3:15:17 ago. (Use '!kill 6788' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8fb85ea8e7f06b8c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8fb85ea8e7f06b8c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6001;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'C:/Users/thoma/Documents/Softwareudvikling/Deep_learning/Eksamensprojekt/kode/DeepLearning/runs'  --host localhost --port 6001\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir logs\n",
    "#Højreklik på runs og ændre stinavn\n",
    "#%load_ext tensorboard \n",
    "#%tensorboard --logdir C:/Users/yusuf/Documents/GitHub/DeepLearning/runs --host localhost --port 6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18824/2562291543.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Forward -> beregner output tensors ved brug af input tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Beregner gradienten udfra output tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18824/417267273.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#max pooling med en pooling shape på 2x2 over det første 2D convolutional layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#max pooling med en pooling shape på 2x2 over det andet 2D convolutional layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Ændrer formen på tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 443\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "n_epochs = 100\n",
    "total_loss = 0\n",
    "total_correct = 0\n",
    "\n",
    "for epoch in range(50):  # looper over dataset 50 gang\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0): #looper igennem data fra vores trainloader\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data #inputs og labels er tensors\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad() #Vores gradient bliver resat (sættes til 0)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels) #Forward -> beregner output tensors ved brug af input tensors\n",
    "        loss.backward() #Beregner gradienten udfra output tensors\n",
    "        total_loss+= loss.item()\n",
    "        total_correct+= get_num_correct(outputs, labels)\n",
    "        optimizer.step() #Optimizeren itererer over parametrene/vores tensors og opdaterer deres gradient \n",
    "\n",
    "        #running_loss += loss.item()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        #.argmax(dim=1).eq(labels).sum().item()\n",
    "        f1_score = f1_score(labels.data.detach().numpy(), outputs.argmax(dim=1))\n",
    "\n",
    "\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            #Tilføjer scalar data til vores tensorboard\n",
    "            writer.add_scalar('Loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(model, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        add_scalars(total_loss, total_correct, training_data, epoch)\n",
    "        writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        writer.add_scalar(\"Accuracy\", total_correct/ len(training_data), epoch)\n",
    "        \n",
    "        print(\"Epoch: %d, Loss: %f\" % (i, float(loss)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/numberplate_experiment')\n",
    "model = Model()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "writer.add_image(\"images\", grid)\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0])\n",
      "epoch: 0 total_correct: 235 loss: 17.988118052482605\n",
      "tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0])\n",
      "epoch: 1 total_correct: 377 loss: 5.049574553966522\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0])\n",
      "epoch: 2 total_correct: 367 loss: 4.837797284126282\n",
      "tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 3 total_correct: 380 loss: 4.831047773361206\n",
      "tensor([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 4 total_correct: 402 loss: 4.776127099990845\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1])\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 5 total_correct: 402 loss: 4.755714178085327\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1])\n",
      "epoch: 6 total_correct: 402 loss: 4.750090062618256\n",
      "tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1])\n",
      "tensor([1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0])\n",
      "epoch: 7 total_correct: 402 loss: 4.743481457233429\n",
      "tensor([1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0])\n",
      "epoch: 8 total_correct: 402 loss: 4.756978929042816\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 9 total_correct: 402 loss: 4.727366328239441\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1])\n",
      "epoch: 10 total_correct: 402 loss: 4.737209796905518\n",
      "tensor([1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1])\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1])\n",
      "epoch: 11 total_correct: 402 loss: 4.7354084849357605\n",
      "tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0])\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0])\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0])\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1])\n",
      "epoch: 12 total_correct: 402 loss: 4.725397884845734\n",
      "tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0])\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1])\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0])\n",
      "epoch: 13 total_correct: 402 loss: 4.765900194644928\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0])\n",
      "tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 14 total_correct: 402 loss: 4.734219908714294\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 1])\n",
      "tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 15 total_correct: 402 loss: 4.714304745197296\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0])\n",
      "tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0])\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1])\n",
      "epoch: 16 total_correct: 402 loss: 4.715531706809998\n",
      "tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1])\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0])\n",
      "tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0])\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1])\n",
      "tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1])\n",
      "epoch: 17 total_correct: 402 loss: 4.720494389533997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18824/990829276.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtotal_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18824/150617039.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py\u001b[0m in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\thoma\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model = Model().to(device)\n",
    "train_loader = torch.utils.data.DataLoader(training_data,batch_size = 100, shuffle = True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "writer = SummaryWriter('runs/numberplate_experiment_2')\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        print(labels)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss+= loss.item()\n",
    "        total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    add_scalars(total_loss, total_correct, training_data, epoch)\n",
    "    writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    writer.add_scalar(\"Accuracy\", total_correct/ len(training_data), epoch)\n",
    "    \n",
    "    writer.add_histogram(\"conv1.bias\", model.conv1.bias, epoch)\n",
    "    writer.add_histogram(\"conv1.weight\", model.conv1.weight, epoch)\n",
    "    writer.add_histogram(\"conv2.bias\", model.conv2.bias, epoch)\n",
    "    writer.add_histogram(\"conv2.weight\", model.conv2.weight, epoch)\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 1\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 316 loss: 27.24612295627594\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 376 loss: 15.49423462152481\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 402 loss: 14.988932490348816\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 376 loss: 15.093316674232483\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 402 loss: 14.973612427711487\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 5 total_correct: 362 loss: 14.885686248540878\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 6 total_correct: 402 loss: 15.269991248846054\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 7 total_correct: 362 loss: 15.692752033472061\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 15.37368756532669\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 9 total_correct: 402 loss: 14.93518751859665\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 14.8727308511734\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 14.906694173812866\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 14.855312943458557\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 14.824025273323059\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 14.836636453866959\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 15.072705149650574\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 15.110590398311615\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 15.17437595129013\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 15.08430302143097\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 15.102617740631104\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 15.037013232707977\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 21 total_correct: 381 loss: 14.729723185300827\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 15.14874118566513\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 23 total_correct: 401 loss: 15.030439019203186\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 24 total_correct: 386 loss: 15.35188215970993\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 14.909622609615326\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 14.976745903491974\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 14.837748944759369\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 15.025039374828339\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 14.980768501758575\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 14.94979453086853\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 14.822648644447327\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 14.73821097612381\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 14.908477008342743\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 15.017691552639008\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 15.062127113342285\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 14.969803094863892\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 15.00972467660904\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 38 total_correct: 357 loss: 15.310273468494415\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 39 total_correct: 402 loss: 14.74041998386383\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 15.153402924537659\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 14.86565774679184\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 15.008902072906494\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 43 total_correct: 322 loss: 15.260993242263794\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 44 total_correct: 402 loss: 14.89528203010559\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 45 total_correct: 402 loss: 14.878711581230164\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 46 total_correct: 402 loss: 15.01843374967575\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 47 total_correct: 402 loss: 14.783277094364166\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 48 total_correct: 402 loss: 14.929664492607117\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 49 total_correct: 402 loss: 14.844818830490112\n",
      "__________________________________________________________\n",
      "run id: 2\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 335 loss: 25.826999127864838\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 385 loss: 14.960508346557617\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 335 loss: 15.524790287017822\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 347 loss: 15.401816189289093\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 402 loss: 15.23347681760788\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 5 total_correct: 402 loss: 15.062700390815735\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 6 total_correct: 402 loss: 15.06289917230606\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 7 total_correct: 402 loss: 15.080287218093872\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 8 total_correct: 384 loss: 15.129623532295227\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 15.10146015882492\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 15.056542158126831\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 15.021176099777222\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 15.026665091514587\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 15.017257332801819\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 15.031144082546234\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 15.014159977436066\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 14.992428243160248\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 14.981804847717285\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 14.97577452659607\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 14.967214167118073\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 14.978069365024567\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 21 total_correct: 388 loss: 14.931118667125702\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 15.050932109355927\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 14.99041086435318\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 14.914150416851044\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 14.919866025447845\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 14.91507750749588\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 14.917996346950531\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 14.907471477985382\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 14.911332190036774\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 14.963963150978088\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 14.936464309692383\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 14.900318801403046\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 14.945954144001007\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 14.84867811203003\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 14.76155573129654\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 14.970159709453583\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 14.803205907344818\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 38 total_correct: 397 loss: 14.907088458538055\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 39 total_correct: 404 loss: 14.798206627368927\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 40 total_correct: 409 loss: 14.822499215602875\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 41 total_correct: 406 loss: 14.592649459838867\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 14.692562729120255\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 43 total_correct: 391 loss: 14.74013078212738\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 15.030935049057007\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 45 total_correct: 403 loss: 14.732714891433716\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 46 total_correct: 406 loss: 14.450595825910568\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 47 total_correct: 409 loss: 14.503732979297638\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 48 total_correct: 405 loss: 14.222720086574554\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 49 total_correct: 396 loss: 14.314313560724258\n",
      "__________________________________________________________\n",
      "run id: 3\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 337 loss: 20.36778074502945\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 393 loss: 8.7060986161232\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 329 loss: 7.784493982791901\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 402 loss: 7.537417352199554\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 402 loss: 7.444059371948242\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 5 total_correct: 402 loss: 7.410155415534973\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 6 total_correct: 402 loss: 7.453758597373962\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 7 total_correct: 402 loss: 7.437232255935669\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 7.458528459072113\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 9 total_correct: 402 loss: 7.427822291851044\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 7.408006548881531\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 7.428192615509033\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 7.468830227851868\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 7.399776995182037\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 7.477014660835266\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 7.621559202671051\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 7.481354713439941\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 7.497084021568298\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 7.417631566524506\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 7.418964266777039\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 7.406615734100342\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 7.439615845680237\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 7.406821608543396\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 7.420716166496277\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 7.40760999917984\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 7.394736111164093\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 7.4141541719436646\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 7.583782851696014\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 7.447692811489105\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 7.478568077087402\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 7.4197699427604675\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 7.435906708240509\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 7.46692031621933\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 7.48918616771698\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 7.479864001274109\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 7.396008133888245\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 7.42534738779068\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 7.434032738208771\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 38 total_correct: 370 loss: 7.547880589962006\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 39 total_correct: 402 loss: 7.5384403467178345\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 7.406643509864807\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 7.362858295440674\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 7.3703333735466\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 43 total_correct: 400 loss: 7.488215446472168\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 44 total_correct: 402 loss: 7.375856578350067\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 45 total_correct: 402 loss: 7.29295814037323\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 46 total_correct: 402 loss: 7.275361955165863\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 47 total_correct: 402 loss: 7.195013344287872\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 48 total_correct: 410 loss: 7.214727103710175\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 49 total_correct: 416 loss: 7.246087074279785\n",
      "__________________________________________________________\n",
      "run id: 4\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 269 loss: 26.199304461479187\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 402 loss: 9.18531721830368\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 312 loss: 8.03967171907425\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 402 loss: 7.438082993030548\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 402 loss: 7.519506633281708\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 5 total_correct: 402 loss: 7.421062529087067\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 6 total_correct: 402 loss: 7.443255424499512\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 7 total_correct: 402 loss: 7.431983709335327\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 8 total_correct: 402 loss: 7.433722972869873\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 7.431460022926331\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 7.43273264169693\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 7.428372442722321\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 7.426719427108765\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 7.421650290489197\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 7.414461851119995\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 15 total_correct: 400 loss: 7.4076828956604\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 16 total_correct: 400 loss: 7.404062390327454\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 17 total_correct: 399 loss: 7.394438803195953\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 18 total_correct: 398 loss: 7.392694652080536\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 19 total_correct: 400 loss: 7.376488208770752\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 20 total_correct: 404 loss: 7.335907697677612\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 21 total_correct: 406 loss: 7.313526928424835\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 22 total_correct: 406 loss: 7.2640188336372375\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 23 total_correct: 416 loss: 7.203446388244629\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 24 total_correct: 421 loss: 7.196692645549774\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 25 total_correct: 419 loss: 7.124206006526947\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 26 total_correct: 420 loss: 7.064876914024353\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 27 total_correct: 436 loss: 6.914196133613586\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 28 total_correct: 446 loss: 6.792410522699356\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 29 total_correct: 444 loss: 6.635895788669586\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 30 total_correct: 462 loss: 6.57894903421402\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 31 total_correct: 468 loss: 6.403050392866135\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 32 total_correct: 485 loss: 6.129487484693527\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 33 total_correct: 484 loss: 6.090818524360657\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 34 total_correct: 454 loss: 6.685883045196533\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 35 total_correct: 458 loss: 6.575327515602112\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 36 total_correct: 489 loss: 6.2346594631671906\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 37 total_correct: 491 loss: 6.012819200754166\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 38 total_correct: 491 loss: 5.951168984174728\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 39 total_correct: 499 loss: 5.855681359767914\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 40 total_correct: 530 loss: 5.107487171888351\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 41 total_correct: 522 loss: 5.202918589115143\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 42 total_correct: 524 loss: 5.081996709108353\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 43 total_correct: 531 loss: 4.996278941631317\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 44 total_correct: 552 loss: 4.769852697849274\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 45 total_correct: 525 loss: 5.214114427566528\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 46 total_correct: 554 loss: 4.459910467267036\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 47 total_correct: 554 loss: 4.213957816362381\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 48 total_correct: 560 loss: 4.149637117981911\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 49 total_correct: 544 loss: 4.583075076341629\n",
      "__________________________________________________________\n",
      "run id: 5\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 253 loss: 13.918532490730286\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 281 loss: 6.070934176445007\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 321 loss: 4.4239848256111145\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 368 loss: 4.318813741207123\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 396 loss: 4.262546360492706\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 5 total_correct: 383 loss: 4.237453401088715\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 6 total_correct: 360 loss: 4.117456674575806\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 7 total_correct: 402 loss: 4.063951253890991\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 4.051453709602356\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 9 total_correct: 402 loss: 4.070101737976074\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 4.096015632152557\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 4.066549301147461\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 4.048374056816101\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 4.066757440567017\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 4.044555604457855\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 4.032756745815277\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 4.010602712631226\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 4.06311297416687\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 4.03149151802063\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 4.036072015762329\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 4.048075556755066\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 4.051516115665436\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 4.0552502274513245\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 4.024989128112793\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 4.045257389545441\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 4.060944497585297\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 4.039011657238007\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 4.06302535533905\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 4.118335068225861\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 4.049633622169495\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 4.099015831947327\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 4.05379855632782\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 4.039618730545044\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 4.043093502521515\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 4.049146234989166\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 4.0718899965286255\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 4.051302790641785\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 4.0431042313575745\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 38 total_correct: 402 loss: 4.014308154582977\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 39 total_correct: 402 loss: 4.062382876873016\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 4.034486711025238\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 4.131460905075073\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 4.083466649055481\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 43 total_correct: 402 loss: 4.077364802360535\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 44 total_correct: 402 loss: 4.0538270473480225\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 45 total_correct: 402 loss: 4.049529075622559\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 46 total_correct: 402 loss: 4.117266237735748\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 47 total_correct: 402 loss: 4.070330619812012\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 48 total_correct: 402 loss: 4.11333554983139\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 49 total_correct: 402 loss: 4.043218433856964\n",
      "__________________________________________________________\n",
      "run id: 6\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 285 loss: 15.378151178359985\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 402 loss: 8.280086815357208\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 402 loss: 4.426855683326721\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 336 loss: 4.167259156703949\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 395 loss: 4.2057042717933655\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 5 total_correct: 361 loss: 4.221942484378815\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 6 total_correct: 352 loss: 4.344079971313477\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 7 total_correct: 331 loss: 4.3802565932273865\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 8 total_correct: 402 loss: 4.180192649364471\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 4.0587278008461\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 4.06889009475708\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 4.063788175582886\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 4.039849162101746\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 4.0500282645225525\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 4.050284922122955\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 4.042554259300232\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 4.043932557106018\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 4.04578173160553\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 4.042967855930328\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 4.042142868041992\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 4.043067395687103\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 4.041925072669983\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 4.041022956371307\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 4.040934085845947\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 4.040439128875732\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 4.039651870727539\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 4.039155602455139\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 4.038696110248566\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 4.037831246852875\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 4.03720623254776\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 4.036539912223816\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 4.03572404384613\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 4.034900724887848\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 4.0342718958854675\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 4.033294856548309\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 4.032505035400391\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 4.031794250011444\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 4.0309388637542725\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 4.030059993267059\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 4.029428780078888\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 40 total_correct: 402 loss: 4.028558671474457\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 41 total_correct: 402 loss: 4.027732253074646\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 4.027082800865173\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 43 total_correct: 402 loss: 4.02634197473526\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 4.025429666042328\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 4.024692714214325\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 46 total_correct: 402 loss: 4.0238834619522095\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 47 total_correct: 402 loss: 4.023183584213257\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 4.022334575653076\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 49 total_correct: 402 loss: 4.02165299654007\n",
      "__________________________________________________________\n",
      "run id: 7\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 249 loss: 69.694366812706\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 342 loss: 17.309981048107147\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 377 loss: 15.52591323852539\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 373 loss: 15.14270967245102\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 388 loss: 15.22866666316986\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 5 total_correct: 370 loss: 16.061803460121155\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 6 total_correct: 348 loss: 15.89016205072403\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 7 total_correct: 389 loss: 15.339850068092346\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 14.668804854154587\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 9 total_correct: 359 loss: 15.595705687999725\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 14.849358886480331\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 11 total_correct: 368 loss: 15.523078799247742\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 15.312410116195679\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 13 total_correct: 402 loss: 14.655120313167572\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 14 total_correct: 357 loss: 15.81518417596817\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 15.059477686882019\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 16 total_correct: 362 loss: 15.026156783103943\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 14.720461010932922\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 15.067691266536713\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 15.006487905979156\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 14.824636936187744\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 14.876446187496185\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 15.019905388355255\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 15.061275720596313\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 14.889180123806\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 15.014958322048187\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 26 total_correct: 387 loss: 14.844173938035965\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 14.904468834400177\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 15.144058346748352\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 15.0471510887146\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 14.811680555343628\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 14.839136362075806\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 14.89994502067566\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 33 total_correct: 403 loss: 14.846647441387177\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 14.648885130882263\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 14.801186621189117\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 36 total_correct: 404 loss: 14.872835278511047\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 14.721978068351746\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 38 total_correct: 406 loss: 14.834915816783905\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 39 total_correct: 403 loss: 14.936002790927887\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 14.855540871620178\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 41 total_correct: 405 loss: 14.632680892944336\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 42 total_correct: 392 loss: 14.874985158443451\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 43 total_correct: 399 loss: 14.782150387763977\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 44 total_correct: 415 loss: 14.820254802703857\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 45 total_correct: 400 loss: 14.832248151302338\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 46 total_correct: 403 loss: 14.71011769771576\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 47 total_correct: 405 loss: 14.66773772239685\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 48 total_correct: 400 loss: 14.736539125442505\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 49 total_correct: 405 loss: 14.710098683834076\n",
      "__________________________________________________________\n",
      "run id: 8\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 291 loss: 66.15405797958374\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 350 loss: 16.388161838054657\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 362 loss: 16.829337775707245\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 408 loss: 14.863054394721985\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 396 loss: 15.068186223506927\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 5 total_correct: 376 loss: 15.152037262916565\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 6 total_correct: 372 loss: 15.147315323352814\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 7 total_correct: 368 loss: 15.151414096355438\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 8 total_correct: 363 loss: 15.168522238731384\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 9 total_correct: 367 loss: 15.171499073505402\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 10 total_correct: 385 loss: 15.167797088623047\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 15.1573925614357\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 15.102912962436676\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 15.068946719169617\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 15.050921142101288\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 15.039245784282684\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 15.028187692165375\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 15.02045089006424\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 15.01175719499588\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 15.005099356174469\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 15.001351356506348\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 14.995350539684296\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 14.98893517255783\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 14.981491446495056\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 14.982640266418457\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 14.973549544811249\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 14.963400065898895\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 14.956632494926453\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 14.950651466846466\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 14.943256497383118\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 14.936256647109985\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 14.92958652973175\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 14.924605548381805\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 14.91793966293335\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 14.909663319587708\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 14.901560842990875\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 14.890824615955353\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 14.87983787059784\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 14.86833119392395\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 14.856213510036469\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 40 total_correct: 403 loss: 14.841430127620697\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 41 total_correct: 405 loss: 14.824855387210846\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 42 total_correct: 405 loss: 14.80804967880249\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 43 total_correct: 405 loss: 14.787438094615936\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 44 total_correct: 404 loss: 14.764843046665192\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 14.740410208702087\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 46 total_correct: 400 loss: 14.716599375009537\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 47 total_correct: 403 loss: 14.686160385608673\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 14.654077976942062\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 49 total_correct: 399 loss: 14.615846186876297\n",
      "__________________________________________________________\n",
      "run id: 9\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 164 loss: 43.363471269607544\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 402 loss: 26.295618891716003\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 347 loss: 9.459377467632294\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 401 loss: 7.885217130184174\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 358 loss: 7.964924693107605\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 5 total_correct: 374 loss: 7.580193817615509\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 6 total_correct: 403 loss: 7.485031604766846\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 7 total_correct: 402 loss: 7.604471921920776\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 8 total_correct: 402 loss: 7.595073699951172\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 9 total_correct: 342 loss: 7.678823411464691\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 10 total_correct: 402 loss: 7.585114896297455\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 11 total_correct: 402 loss: 7.518393516540527\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 12 total_correct: 402 loss: 7.554508924484253\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 13 total_correct: 403 loss: 7.525681793689728\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 14 total_correct: 402 loss: 7.484487593173981\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 15 total_correct: 402 loss: 7.472942113876343\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 16 total_correct: 402 loss: 7.44753897190094\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 17 total_correct: 402 loss: 7.414145112037659\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 7.480726182460785\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 19 total_correct: 402 loss: 7.455009937286377\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 20 total_correct: 402 loss: 7.472830593585968\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 21 total_correct: 402 loss: 7.450009763240814\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 22 total_correct: 402 loss: 7.482929468154907\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 23 total_correct: 402 loss: 7.435028672218323\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 7.449386477470398\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 7.474413752555847\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 7.417469143867493\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 7.400317430496216\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 7.419285356998444\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 7.4387858510017395\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 7.476082384586334\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 7.390245079994202\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 7.49998539686203\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 7.435087621212006\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 7.423947334289551\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 7.4363632798194885\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 7.40404212474823\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 37 total_correct: 402 loss: 7.395208716392517\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 38 total_correct: 402 loss: 7.424441993236542\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 39 total_correct: 404 loss: 7.513106822967529\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 40 total_correct: 402 loss: 7.3528507351875305\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 41 total_correct: 402 loss: 7.373942792415619\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 42 total_correct: 403 loss: 7.379277527332306\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 43 total_correct: 404 loss: 7.466032445430756\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 44 total_correct: 404 loss: 7.293300747871399\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 45 total_correct: 405 loss: 7.335013687610626\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 46 total_correct: 410 loss: 7.275436520576477\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 47 total_correct: 406 loss: 7.21469783782959\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 48 total_correct: 405 loss: 7.2302141189575195\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 49 total_correct: 392 loss: 7.31055074930191\n",
      "__________________________________________________________\n",
      "run id: 10\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 116 loss: 43.830933570861816\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 410 loss: 20.264520347118378\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 359 loss: 8.498886585235596\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 408 loss: 7.465622246265411\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 356 loss: 8.032836318016052\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 5 total_correct: 407 loss: 7.480553388595581\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 6 total_correct: 387 loss: 7.647056579589844\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 7 total_correct: 402 loss: 7.573605477809906\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 8 total_correct: 400 loss: 7.530215203762054\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 9 total_correct: 401 loss: 7.555724322795868\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 7.568820774555206\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 11 total_correct: 389 loss: 7.583356022834778\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 12 total_correct: 385 loss: 7.6292884349823\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 13 total_correct: 365 loss: 7.722759008407593\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 14 total_correct: 344 loss: 7.822085678577423\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 15 total_correct: 351 loss: 7.869375109672546\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 7.724709331989288\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 7.5004711747169495\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 18 total_correct: 403 loss: 7.549408316612244\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 19 total_correct: 403 loss: 7.589342772960663\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 20 total_correct: 403 loss: 7.58121383190155\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 7.571530640125275\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 7.568197667598724\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 23 total_correct: 403 loss: 7.561914086341858\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 24 total_correct: 403 loss: 7.55134654045105\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 25 total_correct: 403 loss: 7.541622161865234\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 26 total_correct: 403 loss: 7.536372363567352\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 27 total_correct: 403 loss: 7.531864106655121\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 7.526395320892334\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 7.5204116106033325\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 7.513915240764618\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 7.507997274398804\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 7.502902388572693\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 7.497766077518463\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 7.492101788520813\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 7.486887156963348\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 7.482308566570282\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 7.47810685634613\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 7.47372043132782\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 7.4693310260772705\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 40 total_correct: 402 loss: 7.464672803878784\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 41 total_correct: 402 loss: 7.460358917713165\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 7.455932378768921\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 43 total_correct: 402 loss: 7.4517799615859985\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 7.447810411453247\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 7.443659663200378\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 46 total_correct: 402 loss: 7.438999891281128\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 47 total_correct: 402 loss: 7.4352598786354065\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 7.431049704551697\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 49 total_correct: 402 loss: 7.426621675491333\n",
      "__________________________________________________________\n",
      "run id: 11\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 114 loss: 23.96440625190735\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 402 loss: 19.72678828239441\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 402 loss: 8.527487516403198\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 347 loss: 4.35051167011261\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 356 loss: 4.174541115760803\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 5 total_correct: 397 loss: 4.085350811481476\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 6 total_correct: 358 loss: 4.229199230670929\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 7 total_correct: 383 loss: 4.141476333141327\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 8 total_correct: 378 loss: 4.1829657554626465\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 9 total_correct: 370 loss: 4.117190062999725\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 10 total_correct: 353 loss: 4.1802122592926025\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 11 total_correct: 374 loss: 4.252385854721069\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 12 total_correct: 373 loss: 4.123814046382904\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 13 total_correct: 376 loss: 4.044641077518463\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 14 total_correct: 369 loss: 4.252564489841461\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 15 total_correct: 391 loss: 4.196823239326477\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 16 total_correct: 400 loss: 4.057255148887634\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 17 total_correct: 403 loss: 4.036999702453613\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 18 total_correct: 402 loss: 4.101633846759796\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 19 total_correct: 341 loss: 4.099148869514465\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 20 total_correct: 363 loss: 4.206672370433807\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 21 total_correct: 388 loss: 4.184188544750214\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 22 total_correct: 401 loss: 4.026743233203888\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 23 total_correct: 401 loss: 4.088083565235138\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 24 total_correct: 402 loss: 4.060262084007263\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 25 total_correct: 402 loss: 4.032184183597565\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 26 total_correct: 402 loss: 4.052981734275818\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 27 total_correct: 402 loss: 4.0298378467559814\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 28 total_correct: 402 loss: 4.085800647735596\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 29 total_correct: 402 loss: 4.082065641880035\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 30 total_correct: 402 loss: 4.0641807317733765\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 31 total_correct: 402 loss: 4.105561673641205\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 32 total_correct: 402 loss: 4.04161673784256\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 33 total_correct: 402 loss: 4.028831958770752\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 34 total_correct: 402 loss: 4.03004777431488\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 35 total_correct: 402 loss: 4.032059371471405\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 36 total_correct: 402 loss: 4.205872476100922\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 37 total_correct: 388 loss: 4.073063433170319\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 38 total_correct: 403 loss: 4.057521104812622\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 39 total_correct: 375 loss: 4.148207247257233\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 40 total_correct: 403 loss: 4.042802572250366\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 41 total_correct: 401 loss: 4.049214780330658\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 42 total_correct: 402 loss: 3.9951016902923584\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 43 total_correct: 403 loss: 4.040547549724579\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 44 total_correct: 401 loss: 4.093116462230682\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 45 total_correct: 401 loss: 4.061325430870056\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 46 total_correct: 403 loss: 4.065863609313965\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 47 total_correct: 403 loss: 4.106115758419037\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 48 total_correct: 405 loss: 4.019805908203125\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 49 total_correct: 403 loss: 4.023688852787018\n",
      "__________________________________________________________\n",
      "run id: 12\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 0 loss: 24.674416065216064\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 349 loss: 23.268605947494507\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 402 loss: 17.18660569190979\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 402 loss: 7.63860958814621\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 335 loss: 5.04662024974823\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 5 total_correct: 381 loss: 4.314918398857117\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 6 total_correct: 360 loss: 4.425480008125305\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 7 total_correct: 380 loss: 4.103124618530273\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 8 total_correct: 402 loss: 4.20444792509079\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 9 total_correct: 402 loss: 4.071534991264343\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 10 total_correct: 402 loss: 4.12193638086319\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 11 total_correct: 402 loss: 4.0686914920806885\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 12 total_correct: 402 loss: 4.089491546154022\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 13 total_correct: 402 loss: 4.0675570368766785\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 14 total_correct: 402 loss: 4.077975213527679\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 15 total_correct: 402 loss: 4.065901100635529\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 16 total_correct: 402 loss: 4.074319779872894\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 17 total_correct: 402 loss: 4.064665973186493\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 18 total_correct: 402 loss: 4.072988152503967\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 19 total_correct: 402 loss: 4.064190030097961\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 20 total_correct: 402 loss: 4.0716217160224915\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 21 total_correct: 402 loss: 4.064895749092102\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 22 total_correct: 402 loss: 4.069674491882324\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 23 total_correct: 402 loss: 4.065991699695587\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 24 total_correct: 402 loss: 4.067696034908295\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 25 total_correct: 402 loss: 4.066888391971588\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 26 total_correct: 402 loss: 4.066313683986664\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 27 total_correct: 402 loss: 4.066775143146515\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 28 total_correct: 402 loss: 4.065880179405212\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 29 total_correct: 402 loss: 4.06610381603241\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 30 total_correct: 402 loss: 4.065442204475403\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 31 total_correct: 402 loss: 4.065295577049255\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 32 total_correct: 402 loss: 4.064584136009216\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 33 total_correct: 402 loss: 4.064287304878235\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 34 total_correct: 402 loss: 4.063662350177765\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 35 total_correct: 402 loss: 4.063196539878845\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 36 total_correct: 402 loss: 4.062453269958496\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 37 total_correct: 402 loss: 4.061942458152771\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 38 total_correct: 402 loss: 4.06119704246521\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 39 total_correct: 402 loss: 4.060689866542816\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 40 total_correct: 402 loss: 4.060076117515564\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 41 total_correct: 402 loss: 4.059165179729462\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 42 total_correct: 402 loss: 4.058498740196228\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 43 total_correct: 402 loss: 4.0577919483184814\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 44 total_correct: 402 loss: 4.056876540184021\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 45 total_correct: 402 loss: 4.05630087852478\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 46 total_correct: 402 loss: 4.055235803127289\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 47 total_correct: 402 loss: 4.0546072125434875\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 48 total_correct: 402 loss: 4.05353844165802\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 49 total_correct: 402 loss: 4.052730083465576\n",
      "__________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "parameters = dict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [32,64,128],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "\n",
    "param_values = [v for v in parameters.values()]\n",
    "\n",
    "for run_id, (lr,batch_size, shuffle) in enumerate(product(*param_values)):\n",
    "    print(\"run id:\", run_id + 1)\n",
    "    model = Model().to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(training_data,batch_size = batch_size, shuffle = shuffle)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    comment = f' batch_size = {batch_size} lr = {lr} shuffle = {shuffle}'\n",
    "    writer = SummaryWriter('runs/numberplate_experiment_3',comment=comment)\n",
    "    for epoch in range(50):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "            total_loss+= loss.item()\n",
    "            total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        add_scalars(total_loss, total_correct, training_data, epoch)\n",
    "        writer.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        writer.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        writer.add_scalar(\"Accuracy\", total_correct/ len(training_data), epoch)\n",
    "\n",
    "        print(\"batch_size:\",batch_size, \"lr:\",lr,\"shuffle:\",shuffle)\n",
    "        print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "    print(\"__________________________________________________________\")\n",
    "\n",
    "    writer.add_hparams(\n",
    "            {\"lr\": lr, \"bsize\": batch_size, \"shuffle\":shuffle},\n",
    "            {\n",
    "                \"accuracy\": total_correct/ len(training_data),\n",
    "                \"loss\": total_loss,\n",
    "            },\n",
    "        )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DEL 4 - OPGAVE 1\n",
    "'''\n",
    "imageData = read_image_data()\n",
    "\n",
    "os.makedirs('MaskedNumberplates', exist_ok=True)\n",
    "\n",
    "for id in imageData:\n",
    "    im = Image.open(imagepath + id.path)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.rectangle([id.xmin,id.ymin, id.xmax,id.ymax], fill=True)\n",
    "\n",
    "    #im = im.( (id.xmin, id.ymin, id.xmax, id.ymax) )\n",
    "    im.save('MaskedNumberplates/' + id.path) \n",
    "    im.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(bb, x):\n",
    "    \"\"\"Creates a mask for the bounding box of same shape as image\"\"\"\n",
    "    rows,cols,*_ = x.shape\n",
    "    Y = np.zeros((rows, cols))\n",
    "    bb = bb.astype(np.int)\n",
    "    Y[bb[0]:bb[2], bb[1]:bb[3]] = 1.\n",
    "    return Y\n",
    "\n",
    "def mask_to_bb(Y):\n",
    "    \"\"\"Convert mask Y to a bounding box, assumes 0 as background nonzero object\"\"\"\n",
    "    cols, rows = np.nonzero(Y)\n",
    "    if len(cols)==0: \n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    top_row = np.min(rows)\n",
    "    left_col = np.min(cols)\n",
    "    bottom_row = np.max(rows)\n",
    "    right_col = np.max(cols)\n",
    "    return np.array([left_col, top_row, right_col, bottom_row], dtype=np.float32)\n",
    "\n",
    "def create_bb_array(x):\n",
    "    \"\"\"Generates bounding box array from a train_df row\"\"\"\n",
    "    return np.array([x[5],x[4],x[7],x[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_bb(read_path,write_path,bb,sz):\n",
    "    \"\"\"Resize an image and its bounding box and write image to new path\"\"\"\n",
    "    im = read_image(read_path)\n",
    "    im_resized = cv2.resize(im, (int(1.49*sz), sz))\n",
    "    Y_resized = cv2.resize(create_mask(bb, im), (int(1.49*sz), sz))\n",
    "    new_path = str(write_path/read_path.parts[-1])\n",
    "    cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n",
    "    return new_path, mask_to_bb(Y_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
